# README
This was an extracurricular project that used hyperspectral brain scans to differentiate between normal and tumor tissue. The data are publicly available at https://hsibraindatabase.iuma.ulpgc.es/ and are described in https://ieeexplore.ieee.org/document/8667294. 

Data reduction is done in "reduce_HSI.ipynb"
- The data preprocessing procedure generally follows that done by Fabelo et al. (2019; https://arxiv.org/pdf/2402.10776.pdf). The raw data consists of 826 frequency bands separated by ~0.7 nm. During data reduction, the first and last few frequency bands were omitted to avoid large instrumental uncertainties. The spectral dimension was further reduced to a sampling of ~7 nm by averaging contiguous bands into 63 broad bands. White and dark images were used for flat fielding and zero-point corrections, respectively. Finally, each pixel was normalized to have a maximum value of unity and a minimum of zero.

- The overall goal was to train a classifier that identified tumor tissue from normal tissue given a hyperspectral image cube with supervised learning. The dimensions of each cube was 17x17x63 (17x17 pixels spatial; 63 spectral) centered on the pixel of interest. The original labeled data contained 4 categories: normal tissue, tumor tissue, hypervascular tissue, and background objects. Hypervascularized tissue was easily distinguishable by eye, and the background material was trivial information. In real-life situations, however, separating tumor from normal tissue, is less obvious and is much more valuable to a surgeon. So I only focused on the tumor and normal tissues for classification.

- The number of examples were evenly sampled for each patient i.e., same number of tumor and normal tissue examples. Training and testing samples consisted of the first 21 and last 8 patients (in numerical order) respectively.

- The model architecture included 3D convolutional layers followed by 2D convolutional layers, each using leaky ReLU activations. Binary crossentropy was minimized with the Adam optimizer. The final model was selected for the epoch that yielded the smallest validation loss. The code for training is given in "training.py" using data in "data/X" and "data/Y". Because of the data limitations, I only provide one example of normal and tumor tissue from the validation set. Plotted in "evaluate_models.ipynb" are the sensitivities, specificities, precisions, accuracies, and F-scores for the 8 patients in the validation set.

## Caveats about this project:
1. The robustness of labeled data was not given based on the grade/stage of the tumor tissue. This may be the reason why patient "056-01/02" yielded the lowest predictive metrics. In the future, one could weight the training examples based on such information; in other words, lower grade tumors could be given more weight since they are not as easy to identify. Furthermore, the selection of training/validation samples were selected arbitrarily, and changing these could provide insight to any systematic biases that may exist.
2. The broad-band averaging was also an arbitrary choice. More elaborate techniques for reducing the spectral dimension (e.g. PCA) should be explored.
3. For simplicity, the only model architectures considered were 3D and 2D CNNs. Other architectures, such as spectral inception modules, would likely provide improvements. In fact, the hyperparameter space was not explored extensively, but this would be imperative for real-world studies.

